{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9dd22a-43db-43c2-a4d8-5ff917670a6a",
   "metadata": {},
   "source": [
    "## Example workflow using Delft3D-Flexible Mesh unstructured grid for an unsteady flow field\n",
    "#### Caitlin R. R. Turner, July 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36aa310-0544-4584-940d-e882821e607b",
   "metadata": {},
   "source": [
    "This workbook provides an example workflow for simulating particle movement in an unsteady flow field using hydrodynamic outputs from the [Delft3D-Flexible Mesh (Delft3DFM)](https://www.deltares.nl/en/software/delft3d-flexible-mesh-suite/) suite. Delft3DFM solves the Navier–Stokes equations for incompressible fluids using the shallow water and Boussinesq approximations via a cell-centered finite volume method.\n",
    "\n",
    "To demonstrate this functionality, the workbook walks through calculations of **water exposure time** for the **Lake Pontchartrain Estuary** in Louisiana (USA). Outputs from a previous model run are provided as text files in the repository.\n",
    "\n",
    "For Delft3DFM flow fields stored in a `.nc` file, a commented-out code block is included below to show how relevant variables can be extracted and formatted for use as *dorado* inputs.\n",
    "\n",
    "**Note:** This workbook is modeled after `unstructured_grid_anuga.ipynb` by Kyle Wright and Jay Jariharan, which provides a thorough walkthrough of the geospatial functions in `particle_track.py` and others in `routines.py`, including guidance on computing exposure times for a region of interest. Please refer to that notebook for detailed information on the underlying functions and methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8ae1ec-0f10-4558-b4c5-da8cfe7a4bd7",
   "metadata": {},
   "source": [
    "### Import necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b362a11-58ba-457d-a069-829f47c0bab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dorado.particle_track'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdorado\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdorado\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparticle_track\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dorado.particle_track'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import xarray as xr\n",
    "import json\n",
    "import dorado\n",
    "import dorado.particle_track as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32777bd-9fd7-4309-a275-38a66a2544de",
   "metadata": {},
   "source": [
    "### Set up model names and folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960dddeb-2489-4b57-93b0-37f10a43d404",
   "metadata": {},
   "source": [
    "First, we begin by setting a name for our model, which names the folder where 'dorado' outputs will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f93d83-7958-436e-9233-d6b1de442c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run = 'run_01'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a698108-2f93-441b-b986-dd9acc22728d",
   "metadata": {},
   "source": [
    "### Load in model outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a23ae1-4740-40c5-ba96-ca58d5bcc017",
   "metadata": {},
   "source": [
    "If we were starting directly from a Delft3DFM output file, this is where we would import the outputs from the model run. These files are included in the examples; however, for anyone interested in repeating the steps used to generate these files, uncomment the block of code below.\n",
    "\n",
    "Here, `path2file` should point to the Delft3DFM output file (e.g., `./FlowFM_map.nc`). This output is a NetCDF file containing flow variables (e.g., `depth`, `u`, `v`, `stage`) defined by the latitude and longitude of each cell center. In our case, those coordinates are expressed in **decimal degrees**, which will be relevant later.\n",
    "\n",
    "This model is a toy model of Lake Pontchartrain (USA) that was created in Delft3D. This toy model can be found [here](https://doi.org/10.4211/hs.2301e151c62d4febb59655885458ab0c) (Turner, 2025),  which is used for this walkthorugh (downloading this is not necessary, but may be helpful when for learning how to apply *dorado* to Delft3D models). A fully calibrated model can be found [here](https://doi.org/10.4211/hs.f1c83ff830bb47c5a7c84e6f5217ea5c) (Turner & Hiatt, 2025b), with the model creation process and applications of these codes outlined in *Water exposure time distributions controlled by freshwater releases in a semi-enclosed estuary* (Turner & Hiatt, 2025a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569abfb1-638e-4996-997c-e2800d9192dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How to convert Delft3DFM outputs to dorado inputs\n",
    "# map_xr = xr.open_dataset('FlowFM_map.nc')\n",
    "# x = map_xr['mesh2d_face_x'].values.astype(np.float32).tolist()\n",
    "# y = map_xr['mesh2d_face_y'].values.astype(np.float32).tolist()\n",
    "# elevation = map_xr['mesh2d_flowelem_bl'].values.astype(np.float32).tolist()\n",
    "# time = map_xr['time'].values.astype(np.float32).tolist()\n",
    "\n",
    "# unstructured = {\n",
    "#     'time': time[1:], 'elevation': elevation,\n",
    "#     'x_face': x, 'y_face': y,\n",
    "#     'timesteps': []}\n",
    "# for i in range(len(time) - 1):\n",
    "#     stage = map_xr['mesh2d_s1'].isel(time=1 + i).values.astype(np.float32)\n",
    "#     depth = map_xr['mesh2d_waterdepth'].isel(time=1 + i).values.astype(np.float32)\n",
    "#     u     = map_xr['mesh2d_ucx'].isel(time=1 + i).values.astype(np.float32)\n",
    "#     v     = map_xr['mesh2d_ucy'].isel(time=1 + i).values.astype(np.float32)\n",
    "\n",
    "#     timestep_data = [stage.tolist(), depth.tolist(), u.tolist(), v.tolist()]\n",
    "#     unstructured['timesteps'].append(timestep_data)\n",
    "    \n",
    "# # Save as JSON\n",
    "# with open('unstructured_model_Delft3DFM.txt', 'w') as f:\n",
    "#     json.dump(unstructured, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31334dce-96ca-4b10-801a-1379c67d2630",
   "metadata": {},
   "source": [
    "Here, we will skip the previous step and instead import the `unstructured_model_Delft3DFM.txt` dictionary directly.\n",
    "\n",
    "To use this application, you will need to save or import the necessary Delft3DFM output variables: `elevation`, `stage`, `u`, and `v.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f8cb4e-1929-4dae-bd06-6613f096f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unstructured = json.load(open('unstructured_model_Delft3DFM.txt'))\n",
    "boundaries = pd.read_csv(r\"D3DFM_example_required_files/boundaries_latlon.csv\") # landboudnary file in d3dfm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008765d2-5455-43e8-8ee0-0a5166850f6f",
   "metadata": {},
   "source": [
    "Now that all data is loaded, lets create the folder where 'dorado' outputs will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d6214-ac2a-4511-99d9-3c72a236260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2folder = model_run\n",
    "os.makedirs(path2folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f80730-cb7c-462e-aeb9-518fbf6303f6",
   "metadata": {},
   "source": [
    "### Change Decimal Degree to UTM Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ad04e-572b-4442-a576-de6c46ad079a",
   "metadata": {},
   "source": [
    "Some users may create their models using decimal degrees, however, UTM (meters) coordinates are more intuitive for this workflow. \n",
    "\n",
    "Below is an example of code that converts Delft3DFM outputs from geographic (latitude/longitude) coordinates to UTM.\n",
    "\n",
    "The UTM zone (`zone`) you use is dependent on your location. An easy website to find this zone can be found [here](https://mapscaping.com/utm-zone-finder/), where you select your domain location on a map. The function `pyproj.Proj()` will be used to convert unstrucutred grid coordinates (`unstructured['y_face']`, `unstructured['x_face']`) and land boundary coordinates (`boundaries['x']`, `boundaries['y']`) decimal degree coordinates (longitude, latitude) to UTM coordinates (x, y). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e9537a-d23d-499f-99c4-e3846ecd99ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Proj\n",
    "# Define UTM Zone\n",
    "utm_proj = Proj(proj='utm', zone=15, ellps='WGS84')\n",
    "\n",
    "# Convert Unstructured Grid lon (unstructured['x_face']) and lat (unstructured['y_face']) to UTM\n",
    "(unstructured['x'], unstructured['y']) = utm_proj(unstructured['x_face'], unstructured['y_face'])\n",
    "unstructured['x'], unstructured['y'] = np.round(unstructured['x'], 2), np.round(unstructured['y'],2)\n",
    "\n",
    "# Convert land boundaries lon (boundaries['x']) and lat (boundaries['y']) to UTM\n",
    "boundaries['x'], boundaries['y'] = utm_proj(boundaries['x'], boundaries['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51d158-d231-49d8-a8a7-b0fa346614d6",
   "metadata": {},
   "source": [
    "### Convert data and coordinates for particle routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c30e52-cd58-4d77-bb21-8957c24e6db6",
   "metadata": {},
   "source": [
    "Now that we have the necessary data, we can convert it into the format required by `dorado`. This process includes gridding the hydrodynamic outputs and transforming the geospatial coordinates into **array index** coordinates.\n",
    "\n",
    "First, we will combine our $(x, y)$ coordinates into a list of tuples. This is the expected format for coordinate inputs in the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4607e-abc9-4417-a9b6-a008da9526eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use list comprehension to convert into tuples\n",
    "coordinates = [(round(float(x), 2), round(float(y), 2))for x, y in zip(unstructured['x'], unstructured['y'])]\n",
    "\n",
    "# Let's see the extent of our domain\n",
    "print(min(unstructured['x']), max(unstructured['x']), \n",
    "      min(unstructured['y']), max(unstructured['y']))\n",
    "# As well as our number of data points\n",
    "print(len(unstructured['x']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50f3be5-19d3-43a9-aebe-f90095beeded",
   "metadata": {},
   "source": [
    "Now, let's grid our unstructured data onto a uniform grid. For this, we use the function `particle_track.unstruct2grid()`, which performs inverse-distance-weighted interpolation to generate a Cartesian grid that matches the spatial extent of our model.\n",
    "\n",
    "To use this function, we need to provide:\n",
    "\n",
    "- A list of coordinates (as tuples).\n",
    "- The unstructured data to be gridded (in this case, we start with `elevation`).\n",
    "- The desired resolution of the output grid (here, we use $100\\,\\text{m}$).\n",
    "- The number of $k$ nearest neighbors to include in the interpolation.  \n",
    "  - If $k = 1$, only the nearest data point is used.\n",
    "  - Higher values (default is $k = 3$) produce smoother interpolated results.\n",
    "\n",
    "The underlying implementation uses `scipy` to build a `cKDTree` from the unstructured input data, which maps data points onto a uniform array. While `cKDTree` is significantly faster than other gridding methods (e.g., `scipy.interpolate.griddata`), constructing the tree can still be computationally expensive for very large datasets or very fine grid resolutions.\n",
    "\n",
    "The outputs of `unstruct2grid()` are:\n",
    "\n",
    "- `myInterp`: the resulting interpolation function, which can be reused to grid additional datasets sharing the same coordinate system, grid resolution, and $k$.\n",
    "- A gridded NumPy array of the interpolated data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b400f0-076e-4057-94f2-85e80cf91fa1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "resolution = 100 # km\n",
    "knn = 5 # nearest neighbors used\n",
    "myInterp, elevation = pt.unstruct2grid(coordinates, unstructured['elevation'], resolution, knn, boundary=boundaries, crop=True)\n",
    "\n",
    "# Let's plot the resulting grid to see what the output looks like:\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "cax = ax.imshow(elevation, vmin=-10, vmax=0)\n",
    "cbar = fig.colorbar(cax, ax=ax, label='Depth (m)',shrink = 0.65)\n",
    "ax.set_xlabel('Longitude Index', fontsize=12)\n",
    "ax.set_ylabel('Latitude Index', fontsize=12)\n",
    "cbar.ax.set_ylabel('Depth (m)', fontsize=12)\n",
    "cbar.set_ticks([0, -5, -10])\n",
    "cbar.set_ticklabels(['0', '5', '10'])\n",
    "ax.set_facecolor('whitesmoke')\n",
    "plt.title('Gridded Depth Array')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38330ee5-0cd1-4d76-86cb-46b215d51826",
   "metadata": {},
   "source": [
    "### Define Particle Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b4c91-2f7e-47d9-8e2d-648787fdd75a",
   "metadata": {},
   "source": [
    "For this example, we aim to calculate the exposure time of **Lake Pontchartrain**. This means we want to seed particles throughout the entire basin. \n",
    "\n",
    "To inject particles at a specific location continuously over a set length of time, refer to the notebook `unstructured_grid_anuga.ipynb`.\n",
    "\n",
    "First, we need to define gridcell types. Instructions for creating this file are provided in the commented-out code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd928b5-a117-4334-a91c-89b861f52efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_initial = np.genfromtxt(r\"D3DFM_example_required_files/celltype_edges.csv\", delimiter=',')\n",
    "celltype_roi = np.genfromtxt(r\"D3DFM_example_required_files/celltype_roi.csv\", delimiter=',')\n",
    "\n",
    "# Note: To make this file, run the code to the gridded elevation, then run this:\n",
    "# cell_type_all = elevation.copy()\n",
    "# cell_type_all[~np.isnan(cell_type_all)] = 1\n",
    "# cell_type_all[np.isnan(cell_type_all)] = 2\n",
    "# np.savetxt(\"required_files/cell_type_all.csv\", cell_type_all.astype(int), delimiter = \",\",fmt=\"%d\")\n",
    "#\n",
    "# Next, go into the csv, and manually change the value of anywhere other than \n",
    "# the region you are investigating. You want to change the 1's to 2's in those spots.\n",
    "# Excel conditional formating makes this task much easier. Make all values of 1 in the script blue.\n",
    "# Then upload this data back here as cell_type_all_lp\n",
    "# celltype_lponly = np.genfromtxt(\"required_files/cell_type_all_lp.csv\", delimiter = \",\")\n",
    "# celltype_lponly[np.isnan(celltype_lponly)] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a900b4-2bf0-4d2c-abb0-ad40cf80c2dc",
   "metadata": {},
   "source": [
    "### Set Locations for Particles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c5b1ba-170c-48f2-9fce-97faba4de9d4",
   "metadata": {},
   "source": [
    "Next, we define the possible locations where particles can be seeded.\n",
    "\n",
    "In this example, particles are seeded only in grid cells marked as valid (i.e., where `celltype_lponly == 1`). These cells are typically used to represent water regions of interest—in this case, Lake Pontchartrain. We initialize a `regions` array of the same shape as `elevation`, which will mark eligible seeding zones.\n",
    "\n",
    "The list `seed_locations` is populated with the `(i, j)` indices of all grid cells that meet the criteria. We then randomly shuffle this list and select a fraction (10%) of the locations to seed particles. This sampling reduces computational cost, especially for large grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d2e2ee-3c6a-478c-9422-7029e8ead089",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = np.zeros_like(elevation, dtype='int')\n",
    "\n",
    "# Find all seed locations where celltype_roi == 1\n",
    "seed_locations = np.argwhere(celltype_roi == 1) \n",
    "regions[celltype_roi == 1] = 1\n",
    "\n",
    "# Identify possible locations to initialize particles. \n",
    "np.random.shuffle(seed_locations)\n",
    "num_seeds = int(len(seed_locations) * 0.10) # This means that 10% of the cells have particles. \n",
    "                                            # For large grid sizes, make this number smaller.\n",
    "                                            # It helps make it manageable\n",
    "\n",
    "selected_seed_locations = seed_locations[:num_seeds]\n",
    "seed_xloc, seed_yloc = zip(*selected_seed_locations)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=400)\n",
    "cax = ax.imshow(elevation, vmin=-25, vmax=0)\n",
    "plt.imshow(regions, cmap='bone', alpha=0.3)\n",
    "plt.scatter(seed_yloc,seed_xloc, s = 0.2, color='darkblue')\n",
    "cbar = fig.colorbar(cax, ax=ax, label='Depth (m)',shrink = 0.65)\n",
    "ax.set_xlabel('Longitude Index', fontsize=12)\n",
    "ax.set_ylabel('Latitude Index', fontsize=12)\n",
    "cbar.ax.set_ylabel('Depth (m)', fontsize=12)\n",
    "cbar.set_ticks([0, -5, -10, -15, -20, -25])\n",
    "cbar.set_ticklabels(['0', '5', '10','15', '20','25'])\n",
    "ax.set_facecolor('whitesmoke')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd05725-e5f8-42b1-b49c-abba3c0b3b3e",
   "metadata": {},
   "source": [
    "### Define model routing parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc5227-e9d0-4451-920f-339ad8cb23ee",
   "metadata": {},
   "source": [
    "Now that we have pre-processed the input data, we can configure the particle routing model.\n",
    "\n",
    "We do this using the `particle_track.modelParams` class, where we populate the relevant attributes to suit our application. This includes specifying the gridded hydrodynamic outputs generated earlier, the grid resolution `dx`, and various tuning parameters that influence the behavior of the random walk.\n",
    "\n",
    "In this example, we use the default values for the random walk parameters: `gamma`, `theta`, and `diff_coeff`. Specifically, we keep at `theta = 1.0` to represent water, as we are interested in computing **water exposure time** within Lake Pontchartrain.\n",
    "\n",
    "We are using 10000 particles. At least $O(10^3)$ are recommended depending on your grid size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70fb968-bdc9-47e6-9fdb-07f9fa101d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = 10000  \n",
    "model_timestep = 3600 # seconds (There are 3600 seconds are in hours. The example model uses hourly outputs)\n",
    "timesteps = (len(unstructured['time'])-1)\n",
    "\n",
    "params = pt.modelParams()\n",
    "params.theta = 1.0\n",
    "params.gamma = 0.05\n",
    "params.diff_coeff = 0.8\n",
    "params.cell_type = np.where(np.isnan(elevation), 2, celltype_initial)\n",
    "params.dx = resolution # 100 m in this case\n",
    "params.dry_depth = 0.01\n",
    "params.verbose = False\n",
    "\n",
    "target_times = np.arange(0, model_timestep * (timesteps + 1), model_timestep)\n",
    "target_times = [int(t) for t in target_times]\n",
    "prev_counts = None # Initialize for particle timing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ebd23-e485-4f0d-ac8f-c0099172d41e",
   "metadata": {},
   "source": [
    "### Run the particle routing for unsteady flow fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90ec535-35ec-4764-a1c3-904e07075c93",
   "metadata": {},
   "source": [
    "Because our model represents an unsteady case (i.e., the flow field varies with time), we initialize the particles at the first-time step and track their movement at each subsequent step. For details on steady flows and/or constant particle injections, refer to the notebook *unstructured_grid_anuga.ipynb*, which provides a thorough overview of the particle routing processes and workflow used in 'dorado'.\n",
    "\n",
    "The output is stored in a dictionary organized into the keys `['xinds']`, `['yinds']`, and `['travel_times']`. These are first indexed by particle ID, and then by iteration number. For example, `walk_data['xinds'][5][10]` returns the x-index for the 6th particle at its 11th iteration. While this function returns a `walk_data` dictionary, the same information is also stored as an attribute of the `particles` class and can be accessed via `particle.walk_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ba42f-dfdb-409c-806c-a3a6c9220e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this may take up to 30 minutes. A copy of the results is provided below.\n",
    "# for i in range(timesteps):\n",
    "#     # Rasterize all data\n",
    "#     stage = myInterp(unstructured['timesteps'][i][0])\n",
    "#     depth = myInterp(unstructured['timesteps'][i][1])\n",
    "#     u = myInterp(unstructured['timesteps'][i][2])\n",
    "#     v = myInterp(unstructured['timesteps'][i][3])\n",
    "\n",
    "#     # Set Dorado parameters\n",
    "#     params.topography = elevation\n",
    "#     params.stage = stage\n",
    "#     params.qx = u * depth\n",
    "#     params.qy = v * depth\n",
    "#     params.u = u\n",
    "#     params.y = v\n",
    "\n",
    "#     # Generate particles\n",
    "#     particle = pt.Particles(params)\n",
    "#     if i == 0:\n",
    "#         particle.generate_particles(particles, seed_xloc, seed_yloc, seed_time=0, method='exact')\n",
    "#     else:\n",
    "#         particle.generate_particles(0, [], [], previous_walk_data=walk_data)\n",
    "\n",
    "#     # Run iteration\n",
    "#     walk_data = particle.run_iteration(target_times[i])\n",
    "#     xi, yi, ti = dorado.routines.get_state(walk_data)\n",
    "\n",
    "#     # Discretely assign timesteps times since for unsteady flows with no new particles added\n",
    "#     # This addresses that particles may move through multiple grid cells at each timestep\n",
    "#     x_key = 'xinds' if 'xinds' in walk_data else 'x_inds'\n",
    "#     t_key = 'travel_times'\n",
    "#     x_lists = walk_data[x_key]\n",
    "#     t_lists = walk_data.get(t_key, [[] for _ in x_lists])\n",
    "#     walk_data[t_key] = t_lists\n",
    "#     if prev_counts is None or len(prev_counts) != len(x_lists):\n",
    "#         prev_counts = [0] * len(x_lists)    \n",
    "#     t_start = target_times[i - 1] if i > 0 else 0\n",
    "#     t_end   = target_times[i]\n",
    "    \n",
    "#     for p, x_list in enumerate(x_lists):\n",
    "#         list_len = len(x_list)\n",
    "#         added = list_len - prev_counts[p]\n",
    "#         if added <= 0:\n",
    "#             continue\n",
    "            \n",
    "#         # Determine starting time \n",
    "#         last_time = t_lists[p][prev_counts[p]-1] if prev_counts[p] > 0 else t_start\n",
    "        \n",
    "#         # Build segment from last_time to t_end\n",
    "#         seg = np.linspace(last_time, t_end, added + 1, endpoint=True)[1:]\n",
    "#         seg = [int(s) if s.is_integer() else float(s) for s in seg]\n",
    "    \n",
    "#         # Grow travel_times if particles move through multiple grid cells\n",
    "#         # within one timestep\n",
    "#         if len(t_lists[p]) < list_len:\n",
    "#             t_lists[p].extend([None] * (list_len - len(t_lists[p])))\n",
    "    \n",
    "#         # Fill the list of timesteps\n",
    "#         t_lists[p][prev_counts[p]:list_len] = seg\n",
    "#         prev_counts[p] = list_len\n",
    "\n",
    "#     # Plotting\n",
    "#     fig, ax = plt.subplots(figsize=(10, 5), dpi=200)\n",
    "#     ax.scatter(yi, xi, c='firebrick', s=1)\n",
    "#     im = ax.imshow(particle.depth * -1, vmin=0, vmax=-25)\n",
    "#     plt.title(f'Time: {int((target_times[i] / 3600) // 24)} Days, {int((target_times[i] / 3600) % 24)} Hours')\n",
    "#     cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "#     cbar.set_label('Depth (m)')\n",
    "#     cbar.set_ticks([0, -5, -10, -15, -20, -25])\n",
    "#     cbar.set_ticklabels(['0', '5', '10', '15', '20', '25'])\n",
    "#     im.axes.xaxis.set_ticklabels([])\n",
    "#     im.axes.yaxis.set_ticklabels([])\n",
    "#     im.axes.get_xaxis().set_ticks([])\n",
    "#     im.axes.get_yaxis().set_ticks([])\n",
    "#     ax.set_facecolor('whitesmoke')\n",
    "#     plt.savefig(f'{path2folder}/output_by_dt{i}.png')\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d7277-6270-4ab4-a0f0-c92d35154a87",
   "metadata": {},
   "source": [
    "If you prefer not to run the code, a file containing the results can be found in this HydroShare [repository](https://doi.org/10.4211/hs.2301e151c62d4febb59655885458ab0c).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb214b3-b01f-40b5-941a-6f4b49de081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{model_run}_WalkData.txt', 'r') as f:\n",
    "    walk_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e54df46-8c71-427e-ac18-b06d1706e74e",
   "metadata": {},
   "source": [
    "Now that we have the walk history stored in `walk_data`, we can query this dictionary to extract features of interest. We can also convert the location indices back into geospatial coordinates using the function `particle_track.ind2coord()`. This function appends two additional fields to the dictionary: `['xcoord']` and `['ycoord']`, which represent particle positions in UTM coordinates, which may be useful for later plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da96cbce-f0de-4053-a4eb-bf0139898336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert particle location indices back into UTM coordinates\n",
    "walk_data = pt.ind2coord(walk_data, \n",
    "                         (min(unstructured['x']), \n",
    "                          min(unstructured['y'])), \n",
    "                         np.shape(elevation), resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c9a5c-09a5-4ea5-93fe-c13877a78a06",
   "metadata": {},
   "source": [
    "### Calculate exposure time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c0422-634a-403f-a9ed-48a72b45d70f",
   "metadata": {},
   "source": [
    "We want to measure the amount of time particles spent \"exposed\" within a Region of Interest (ROI), in our case, Lake Pontchartrain. We will use the region where particles were initially seeded as our area of interest. This allows us to evaluate how long particles remain within the system as a whole. Other ways of defining regions of interest can be found in `unstructured_grid_anuga.ipynb`. \n",
    "\n",
    "To compute this, we use the functions `particle_track.exposure_time()` and `routines.plot_exposure_time()`. These functions calculate and visualize the **Cumulative Distribution Function (CDF)** and the **Exposure Time Distribution (ETD)** based on particle interactions with a defined region of interest (ROI).\n",
    "\n",
    "First, we will compute the exposure times using the `exposure_time()` function. This function outputs a list of exposure times indexed by particle ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e25ab-4b5c-4b7e-a928-64aedc322f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_times = pt.exposure_time(walk_data, regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e008508-2c1c-48fc-9a2d-d106d736c58b",
   "metadata": {},
   "source": [
    "Now, we will visualize the results by calling `plot_exposure_time()`, which generates both the CDF and ETD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6eaec-9cd0-404b-8bb6-9fe4f046efb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exposure_times_plot = dorado.routines.plot_exposure_time(walk_data, \n",
    "                                                         exposure_times, \n",
    "                                                         f'{path2folder}/{model_run}/figs', # Output location for figures\n",
    "                                                         timedelta=86400, # timestep for model in seconds (1 day = 86400 seconds)\n",
    "                                                         nbins=10, # Binning for CDF exposure time\n",
    "                                                         uniform_timesteps = True) # This should be toggled to 'True' when the process used in this\n",
    "                                                                                   # notebook for unsteady data is used. Only toggle this if exposure\n",
    "                                                                                   # timesteps were discretely assigned. Otherwise use default (False)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec659b4-2d7d-4475-a0f9-75c7f4e720b6",
   "metadata": {},
   "source": [
    "**Note:** If any particles are still in the ROI at the end of their travel history, they are excluded from plots. These particles are not done being \"exposed,\" so we need to run more iterations in order to capture the tail of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cebc9d6-5bdf-4ad2-93c5-2225c8b6fdbc",
   "metadata": {},
   "source": [
    "## Save `walk_data` for use with additional model capabilities\n",
    "\n",
    "If you plan to use extended features of the model, such as reprocessing particle paths, calculating spatial exposure time, or generating animations, be sure to save the `walk_data` dictionary for future use.\n",
    "\n",
    "**Note:** While this function returns a `walk_data` dictionary, the same information is also stored as an attribute of the `particles` class and can be accessed via `particle.walk_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f40a3-7a01-4fb0-8649-7186e110b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#json.dump(walk_data, open(f'{model_run}_WalkData.txt', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc58e5d3-8b87-4e9f-86cc-307d4e42553e",
   "metadata": {},
   "source": [
    "Save the following variables if you plan to run spatial exposure time calculations using `spatial.py`, where a walkthrough can be found in `spatial_exposure_time_example_Delft3DFM.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab246a3-d85f-4325-9c26-bdd28ababa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('unstructured_model_Delft3DFM_variables.npz', elevation=elevation, celltype = celltype_roi, exposure_times = exposure_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f7a555-1266-43c8-bf70-bb744cd3a407",
   "metadata": {},
   "source": [
    "If you have any questions, feel free to contact Caitlin R. R. Turner at cturn65@lsu.edu "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e2e7d7-4360-4021-855f-47659f2de7af",
   "metadata": {},
   "source": [
    "#### **Cited:**\n",
    "Turner, C. R. R. (2025). Lake Pontchartrain Toy Model, HydroShare, https://doi.org/10.4211/hs.2301e151c62d4febb59655885458ab0c\n",
    "\n",
    "Turner, C. R. R., & Hiatt, M. (2025a). Water exposure time distributions controlled by freshwater releases in a semi-enclosed estuary. Water Resources Research, 61 (7), e2025WR040287, https://doi.org/10.1029/2025WR040287\n",
    "\n",
    "Turner, C. R. R., & Hiatt, M. (2025b). Water exposure time distributions controlled by freshwater releases in a semi-enclosed estuary published in water resources research wrr 2025 data. Hydroshare. https://doi:10.4211/hs.f1c83ff830bb47c5a7c84e6f5217ea5c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd9703-0a33-4383-aaa6-9e12e2937b0c",
   "metadata": {},
   "source": [
    "#### **Acknowledgments:**\n",
    "This work has been partially supported with funding provided by the Louisiana Sea Grant College Program (LSG) under its Competitive Research Program (Project ID: R/TMA-03) and NOAA Award No. NA18OAR4170098, and through the US Department of Defense/Army Engineer Research and Development Center (ERDC) under Contract No. W912HZ2220005. Additional support was provided from the National Science Foundation (NSF) through Open Earthscape (Collaborative Research: Frameworks: OpenEarthscape - Transformative Cyberinfrastructure for Modeling and Simulation in the Earth-Surface Science Communities) under its Summer Research Scholars Program under award No. 2104102."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:modeling_tools]",
   "language": "python",
   "name": "conda-env-modeling_tools-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
