{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9dd22a-43db-43c2-a4d8-5ff917670a6a",
   "metadata": {},
   "source": [
    "## Example workflow using Delft3D-Flexible Mesh unstructured grid for an unsteady flow field\n",
    "#### Caitlin R. R. Turner, July 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36aa310-0544-4584-940d-e882821e607b",
   "metadata": {},
   "source": [
    "This workbook provides an example workflow for simulating particle movement in an unsteady flow field using hydrodynamic outputs from the [Delft3D-Flexible Mesh (Delft3DFM)](https://www.deltares.nl/en/software/delft3d-flexible-mesh-suite/) suite. Delft3DFM solves the Navier–Stokes equations for incompressible fluids using the shallow water and Boussinesq approximations via a cell-centered finite volume method.\n",
    "\n",
    "To demonstrate this functionality, the workbook walks through calculations of **water exposure time** for the **Lake Pontchartrain Estuary** in Louisiana (USA). Outputs from a previous model run are provided as text files in the repository.\n",
    "\n",
    "For Delft3DFM flow fields stored in a `.nc` file, a commented-out code block is included below to show how relevant variables can be extracted and formatted for use as *dorado* inputs.\n",
    "\n",
    "**Note:** This workbook is modeled after `unstructured_grid_anuga.ipynb` by Kyle Wright and Jay Jariharan, which provides a thorough walkthrough of the geospatial functions in `particle_track.py` and others in `routines.py`, including guidance on computing exposure times for a region of interest. Please refer to that notebook for detailed information on the underlying functions and methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8ae1ec-0f10-4558-b4c5-da8cfe7a4bd7",
   "metadata": {},
   "source": [
    "### Import necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b362a11-58ba-457d-a069-829f47c0bab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import xarray as xr\n",
    "    from pyproj import Proj\n",
    "except ImportError:\n",
    "    # Install missing packages\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install pandas xarray pyproj\n",
    "    import pandas as pd\n",
    "    import xarray as xr\n",
    "    from pyproj import Proj\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import dorado\n",
    "import dorado.particle_track as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008765d2-5455-43e8-8ee0-0a5166850f6f",
   "metadata": {},
   "source": [
    "#### Download Necessary Files and Define Folders\n",
    "To use this notebook, the data folder **D3DFM_example_required_files** needs to be downloaded from HydroShare which can be found [here](https://doi.org/10.4211/hs.2301e151c62d4febb59655885458ab0c). Download the folder into your work folder and copy the path into the variable `data_folder_path` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc1a20-a2c1-4d59-b5d3-c71fc88dfbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(r\"C:/Users/cturn/Documents/CSDMS/Dorado_Project/notebook_final/D3DFM_example_required_files\")\n",
    "#data_folder = Path(r\"Documents/D3DFM_example_required_files\") # Change to your path\n",
    "model_run = \"run_01\"\n",
    "\n",
    "path2folder = data_folder / model_run\n",
    "path2folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a23ae1-4740-40c5-ba96-ca58d5bcc017",
   "metadata": {},
   "source": [
    "#### Load Delft3D Model Files\n",
    "If we were starting directly from a Delft3DFM output file, this is where we would import the outputs from the model run. These files are included in the HydroShare folder; however, for anyone interested in repeating the steps used to generate these files, uncomment the block of code below.\n",
    "\n",
    "Here, `path2file` should point to the Delft3D-FM map output file (e.g., `./FlowFM_map.nc`). This file is a NetCDF dataset containing model results. The following variables are required, with their corresponding Delft3D-FM names shown in brackets:\n",
    "- `x_face` [`mesh2d_face_x`]: x-coordinate of face centers (longitude, float array)  \n",
    "- `y_face` [`mesh2d_face_y`]: y-coordinate of face centers (latitude, float array)  \n",
    "- `elevation` [`mesh2d_flowelem_bl`]: bed elevation (float array)  \n",
    "- `time` [`time`]: model output times (float or datetime array)  \n",
    "- `stage` [`mesh2d_s1`]: water surface elevation (2D array: time × face)  \n",
    "- `depth` [`mesh2d_waterdepth`]: total water depth from bed (2D array: time × face)  \n",
    "- `u` [`mesh2d_ucx`]: velocity component in the x-direction (2D array: time × face)  \n",
    "- `v` [`mesh2d_ucy`]: velocity component in the y-direction (2D array: time × face)  \n",
    "\n",
    "\n",
    "These are defined by the latitude and longitude of each cell center. In our case, those coordinates are expressed in **decimal degrees**, which will be relevant later. \n",
    "\n",
    "The model used in this notebook is a toy model of Lake Pontchartrain (USA) that was created in Delft3D. This toy model can be found [here](https://doi.org/10.4211/hs.2301e151c62d4febb59655885458ab0c) (Turner, 2025),  which is used for this walkthorugh (downloading this is not necessary, but may be helpful when for learning how to apply *dorado* to Delft3D models). A fully calibrated model can be found [here](https://doi.org/10.4211/hs.f1c83ff830bb47c5a7c84e6f5217ea5c) (Turner & Hiatt, 2025b), with the model creation process and applications of these codes outlined in *Water exposure time distributions controlled by freshwater releases in a semi-enclosed estuary* (Turner & Hiatt, 2025a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569abfb1-638e-4996-997c-e2800d9192dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # How to convert Delft3DFM outputs to dorado inputs\n",
    "# map_xr = xr.open_dataset(data_folder / \"FlowFM_map.nc\")\n",
    "# x = map_xr['mesh2d_face_x'].values.astype(np.float32).tolist()\n",
    "# y = map_xr['mesh2d_face_y'].values.astype(np.float32).tolist()\n",
    "# elevation = map_xr['mesh2d_flowelem_bl'].values.astype(np.float32).tolist()\n",
    "# time = map_xr['time'].values.astype(np.float32).tolist()\n",
    "\n",
    "# unstructured = {\n",
    "#     'time': time[1:], 'elevation': elevation,\n",
    "#     'x_face': x, 'y_face': y,\n",
    "#     'timesteps': []}\n",
    "# for i in range(len(time) - 1):\n",
    "#     stage = map_xr['mesh2d_s1'].isel(time=1 + i).values.astype(np.float32)\n",
    "#     depth = map_xr['mesh2d_waterdepth'].isel(time=1 + i).values.astype(np.float32)\n",
    "#     u     = map_xr['mesh2d_ucx'].isel(time=1 + i).values.astype(np.float32)\n",
    "#     v     = map_xr['mesh2d_ucy'].isel(time=1 + i).values.astype(np.float32)\n",
    "\n",
    "#     timestep_data = [stage.tolist(), depth.tolist(), u.tolist(), v.tolist()]\n",
    "#     unstructured['timesteps'].append(timestep_data)\n",
    "    \n",
    "# # Save as JSON\n",
    "# with open(data_folder / f'unstructured_model_Delft3DFM_{model_run}.txt', 'w') as f:\n",
    "#     json.dump(unstructured, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31334dce-96ca-4b10-801a-1379c67d2630",
   "metadata": {},
   "source": [
    "Here, we will skip the previous step and instead import the `unstructured_model_Delft3DFM.txt` dictionary directly from your working directory.  \n",
    "\n",
    "In addition to the model folder, you will also need the land boundaries file, which we call `boundaries`. This file is located in your model inputs folder (e.g., `FlowFM/input/FlowFM.ldb`) and is typically stored in a Microsoft Access database format.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f8cb4e-1929-4dae-bd06-6613f096f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unstructured = json.load(open(data_folder / 'unstructured_model_Delft3DFM_{model_run}.txt'))\n",
    "boundaries = pd.read_csv(data_folder / \"boundaries_latlon.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f80730-cb7c-462e-aeb9-518fbf6303f6",
   "metadata": {},
   "source": [
    "### Change Decimal Degree to UTM Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ad04e-572b-4442-a576-de6c46ad079a",
   "metadata": {},
   "source": [
    "Some models are defined in decimal degrees, but UTM (meters) is more convenient for this workflow.\n",
    "\n",
    "The example below converts Delft3D-FM outputs from geographic (latitude/longitude) to UTM. Choose the UTM zone (`zone`) for your domain. An easy website to find this zone can be found [here](https://mapscaping.com/utm-zone-finder/), where you select your domain location on a map. We will use `pyproj` to convert unstructured grid coordinates (`unstructured['y_face']`, `unstructured['x_face']`) and land-boundary coordinates (`boundaries['x']`, `boundaries['y']`) from decimal degrees (longitude, latitude) to UTM eastings (x) and northings (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e9537a-d23d-499f-99c4-e3846ecd99ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define UTM Zone\n",
    "utm_proj = Proj(proj='utm', zone=15, ellps='WGS84')\n",
    "\n",
    "# Convert Unstructured Grid lon (unstructured['x_face']) and lat (unstructured['y_face']) to UTM\n",
    "(unstructured['x'], unstructured['y']) = utm_proj(unstructured['x_face'], unstructured['y_face'])\n",
    "unstructured['x'], unstructured['y'] = np.round(unstructured['x'], 2), np.round(unstructured['y'],2)\n",
    "\n",
    "# Convert land boundaries lon (boundaries['x']) and lat (boundaries['y']) to UTM\n",
    "boundaries['x'], boundaries['y'] = utm_proj(boundaries['x'], boundaries['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51d158-d231-49d8-a8a7-b0fa346614d6",
   "metadata": {},
   "source": [
    "### Convert data and coordinates for particle routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c30e52-cd58-4d77-bb21-8957c24e6db6",
   "metadata": {},
   "source": [
    "Now that we have the necessary data, we can convert it into the format required by `dorado`. This process includes gridding the hydrodynamic outputs and transforming the geospatial coordinates into **array index** coordinates.\n",
    "\n",
    "First, we will combine our $(x, y)$ coordinates into a list of tuples. This is the expected format for coordinate inputs in the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4607e-abc9-4417-a9b6-a008da9526eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use list comprehension to convert into tuples\n",
    "coordinates = [(round(float(x), 2), round(float(y), 2))for x, y in zip(unstructured['x'], unstructured['y'])]\n",
    "\n",
    "# Let's see the extent of our domain\n",
    "print(min(unstructured['x']), max(unstructured['x']), \n",
    "      min(unstructured['y']), max(unstructured['y']))\n",
    "# As well as our number of data points\n",
    "print(len(unstructured['x']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50f3be5-19d3-43a9-aebe-f90095beeded",
   "metadata": {},
   "source": [
    "Now, let's grid our unstructured data onto a uniform grid. For this, we use the function `particle_track.unstruct2grid()`, which performs inverse-distance-weighted interpolation to generate a Cartesian grid that matches the spatial extent of our model.\n",
    "\n",
    "To use this function, we need to provide:\n",
    "\n",
    "- A list of coordinates (as tuples).\n",
    "- The unstructured data to be gridded (in this case, we start with `elevation`).\n",
    "- The desired resolution of the output grid (here, we use $100\\,\\text{m}$).\n",
    "- The number of $k$ nearest neighbors to include in the interpolation.  \n",
    "  - If $k = 1$, only the nearest data point is used.\n",
    "  - Higher values (default is $k = 3$) produce smoother interpolated results.\n",
    "\n",
    "The underlying implementation uses `scipy` to build a `cKDTree` from the unstructured input data, which maps data points onto a uniform array. While `cKDTree` is significantly faster than other gridding methods (e.g., `scipy.interpolate.griddata`), constructing the tree can still be computationally expensive for very large datasets or very fine grid resolutions.\n",
    "\n",
    "The outputs of `unstruct2grid()` are:\n",
    "\n",
    "- `myInterp`: the resulting interpolation function, which can be reused to grid additional datasets sharing the same coordinate system, grid resolution, and $k$.\n",
    "- A gridded NumPy array of the interpolated data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b400f0-076e-4057-94f2-85e80cf91fa1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "resolution = 100 # km\n",
    "knn = 5 # nearest neighbors used\n",
    "myInterp, elevation = pt.unstruct2grid(coordinates, unstructured['elevation'], resolution, knn, boundary=boundaries, crop=True)\n",
    "\n",
    "# Let's plot the resulting grid to see what the output looks like:\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=300)\n",
    "cax = ax.imshow(elevation, vmin=-10, vmax=0)\n",
    "cbar = fig.colorbar(cax, ax=ax, label='Depth (m)',shrink = 0.65)\n",
    "ax.set_xlabel('Longitude Index', fontsize=12)\n",
    "ax.set_ylabel('Latitude Index', fontsize=12)\n",
    "cbar.ax.set_ylabel('Depth (m)', fontsize=12)\n",
    "cbar.set_ticks([0, -5, -10])\n",
    "cbar.set_ticklabels(['0', '5', '10'])\n",
    "ax.set_facecolor('whitesmoke')\n",
    "plt.title('Gridded Depth Array')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38330ee5-0cd1-4d76-86cb-46b215d51826",
   "metadata": {},
   "source": [
    "### Define Particle Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b4c91-2f7e-47d9-8e2d-648787fdd75a",
   "metadata": {},
   "source": [
    "For this example, we aim to calculate the exposure time of **Lake Pontchartrain**. This means we want to seed particles throughout the entire basin. \n",
    "\n",
    "To inject particles at a specific location continuously over a set length of time, refer to the notebook `unstructured_grid_anuga.ipynb`.\n",
    "\n",
    "First, we need to define gridcell types. Instructions for creating this file are provided in the commented-out code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd928b5-a117-4334-a91c-89b861f52efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_initial = np.genfromtxt(data_folder / \"celltype_edges.csv\", delimiter=',')\n",
    "celltype_roi = np.genfromtxt(data_folder / \"celltype_roi.csv\", delimiter=',')\n",
    "\n",
    "# Note: To make this file, run the code to the gridded elevation, then run this:\n",
    "# cell_type_all = elevation.copy()\n",
    "# cell_type_all[~np.isnan(cell_type_all)] = 1\n",
    "# cell_type_all[np.isnan(cell_type_all)] = 2\n",
    "# np.savetxt(\"required_files/cell_type_all.csv\", cell_type_all.astype(int), delimiter = \",\",fmt=\"%d\")\n",
    "#\n",
    "# Next, go into the csv, and manually change the value of anywhere other than \n",
    "# the region you are investigating. You want to change the 1's to 2's in those spots.\n",
    "# Excel conditional formating makes this task much easier. Make all values of 1 in the script blue.\n",
    "# Then upload this data back here as cell_type_all_lp\n",
    "# celltype_lponly = np.genfromtxt(\"required_files/cell_type_all_lp.csv\", delimiter = \",\")\n",
    "# celltype_lponly[np.isnan(celltype_lponly)] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a900b4-2bf0-4d2c-abb0-ad40cf80c2dc",
   "metadata": {},
   "source": [
    "### Set Locations for Particles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c5b1ba-170c-48f2-9fce-97faba4de9d4",
   "metadata": {},
   "source": [
    "Next, we define the possible locations where particles can be seeded.\n",
    "\n",
    "In this example, particles are seeded only in grid cells marked as valid (i.e., where `celltype_lponly == 1`). These cells are typically used to represent water regions of interest—in this case, Lake Pontchartrain. We initialize a `regions` array of the same shape as `elevation`, which will mark eligible seeding zones.\n",
    "\n",
    "The list `seed_locations` is populated with the `(i, j)` indices of all grid cells that meet the criteria. We then randomly shuffle this list and select a fraction (10%) of the locations to seed particles. This sampling reduces computational cost, especially for large grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d2e2ee-3c6a-478c-9422-7029e8ead089",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = np.zeros_like(elevation, dtype='int')\n",
    "\n",
    "# Find all seed locations where celltype_roi == 1\n",
    "seed_locations = np.argwhere(celltype_roi == 1) \n",
    "regions[celltype_roi == 1] = 1\n",
    "\n",
    "# Identify possible locations to initialize particles. \n",
    "np.random.shuffle(seed_locations)\n",
    "num_seeds = int(len(seed_locations) * 0.10) # This means that 10% of the cells have particles. \n",
    "                                            # For large grid sizes, make this number smaller.\n",
    "                                            # It helps make it manageable\n",
    "\n",
    "selected_seed_locations = seed_locations[:num_seeds]\n",
    "seed_xloc, seed_yloc = zip(*selected_seed_locations)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=400)\n",
    "cax = ax.imshow(elevation, vmin=-25, vmax=0)\n",
    "plt.imshow(regions, cmap='bone', alpha=0.3)\n",
    "plt.scatter(seed_yloc,seed_xloc, s = 0.2, color='darkblue')\n",
    "cbar = fig.colorbar(cax, ax=ax, label='Depth (m)',shrink = 0.65)\n",
    "ax.set_xlabel('Longitude Index', fontsize=12)\n",
    "ax.set_ylabel('Latitude Index', fontsize=12)\n",
    "cbar.ax.set_ylabel('Depth (m)', fontsize=12)\n",
    "cbar.set_ticks([0, -5, -10, -15, -20, -25])\n",
    "cbar.set_ticklabels(['0', '5', '10','15', '20','25'])\n",
    "ax.set_facecolor('whitesmoke')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd05725-e5f8-42b1-b49c-abba3c0b3b3e",
   "metadata": {},
   "source": [
    "### Define model routing parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc5227-e9d0-4451-920f-339ad8cb23ee",
   "metadata": {},
   "source": [
    "Now that we have pre-processed the input data, we can configure the particle routing model.\n",
    "\n",
    "We do this using the `particle_track.modelParams` class, where we populate the relevant attributes to suit our application. This includes specifying the gridded hydrodynamic outputs generated earlier, the grid resolution `dx`, and various tuning parameters that influence the behavior of the random walk.\n",
    "\n",
    "In this example, we use the default values for the random walk parameters: `gamma`, `theta`, and `diff_coeff`. Specifically, we keep at `theta = 1.0` to represent water, as we are interested in computing **water exposure time** within Lake Pontchartrain.\n",
    "\n",
    "We are using 10000 particles. At least $O(10^3)$ are recommended depending on your grid size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70fb968-bdc9-47e6-9fdb-07f9fa101d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles = 10000  \n",
    "model_timestep = 3600 # seconds (There are 3600 seconds are in hours. The example model uses hourly outputs)\n",
    "timesteps = (len(unstructured['time'])-1)\n",
    "\n",
    "params = pt.modelParams()\n",
    "params.theta = 1.0\n",
    "params.gamma = 0.05\n",
    "params.diff_coeff = 0.8\n",
    "params.cell_type = np.where(np.isnan(elevation), 2, celltype_initial)\n",
    "params.dx = resolution # 100 m in this case\n",
    "params.dry_depth = 0.01\n",
    "params.verbose = False\n",
    "\n",
    "target_times = np.arange(0, model_timestep * (timesteps + 1), model_timestep)\n",
    "target_times = [int(t) for t in target_times]\n",
    "prev_counts = None # Initialize for particle timing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ebd23-e485-4f0d-ac8f-c0099172d41e",
   "metadata": {},
   "source": [
    "### Run the particle routing for unsteady flow fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90ec535-35ec-4764-a1c3-904e07075c93",
   "metadata": {},
   "source": [
    "Because our model represents an unsteady case (i.e., the flow field varies with time), we initialize the particles at the first-time step and track their movement at each subsequent step. For details on steady flows and/or constant particle injections, refer to the notebook *unstructured_grid_anuga.ipynb*, which provides a thorough overview of the particle routing processes and workflow used in 'dorado'.\n",
    "\n",
    "The output is stored in a dictionary organized into the keys `['xinds']`, `['yinds']`, and `['travel_times']`. These are first indexed by particle ID, and then by iteration number. For example, `walk_data['xinds'][5][10]` returns the x-index for the 6th particle at its 11th iteration. While this function returns a `walk_data` dictionary, the same information is also stored as an attribute of the `particles` class and can be accessed via `particle.walk_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ba42f-dfdb-409c-806c-a3a6c9220e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Running this may take up to 30 minutes. A copy of the results is provided below.\n",
    "# for i in range(timesteps):\n",
    "#     # Rasterize all data\n",
    "#     stage = myInterp(unstructured['timesteps'][i][0])\n",
    "#     depth = myInterp(unstructured['timesteps'][i][1])\n",
    "#     u = myInterp(unstructured['timesteps'][i][2])\n",
    "#     v = myInterp(unstructured['timesteps'][i][3])\n",
    "\n",
    "#     # Set Dorado parameters\n",
    "#     params.topography = elevation\n",
    "#     params.stage = stage\n",
    "#     params.qx = u * depth\n",
    "#     params.qy = v * depth\n",
    "#     params.u = u\n",
    "#     params.y = v\n",
    "\n",
    "#     # Generate particles\n",
    "#     particle = pt.Particles(params)\n",
    "#     if i == 0:\n",
    "#         particle.generate_particles(particles, seed_xloc, seed_yloc, seed_time=0, method='exact')\n",
    "#     else:\n",
    "#         particle.generate_particles(0, [], [], previous_walk_data=walk_data)\n",
    "\n",
    "#     # Run iteration\n",
    "#     walk_data = particle.run_iteration(target_times[i])\n",
    "#     xi, yi, ti = dorado.routines.get_state(walk_data)\n",
    "\n",
    "#     # Discretely assign timesteps times since for unsteady flows with no new particles added\n",
    "#     # This addresses that particles may move through multiple grid cells at each timestep\n",
    "#     x_key = 'xinds' if 'xinds' in walk_data else 'x_inds'\n",
    "#     t_key = 'travel_times'\n",
    "#     x_lists = walk_data[x_key]\n",
    "#     t_lists = walk_data.get(t_key, [[] for _ in x_lists])\n",
    "#     walk_data[t_key] = t_lists\n",
    "#     if prev_counts is None or len(prev_counts) != len(x_lists):\n",
    "#         prev_counts = [0] * len(x_lists)    \n",
    "#     t_start = target_times[i - 1] if i > 0 else 0\n",
    "#     t_end   = target_times[i]\n",
    "    \n",
    "#     for p, x_list in enumerate(x_lists):\n",
    "#         list_len = len(x_list)\n",
    "#         added = list_len - prev_counts[p]\n",
    "#         if added <= 0:\n",
    "#             continue\n",
    "            \n",
    "#         # Determine starting time \n",
    "#         last_time = t_lists[p][prev_counts[p]-1] if prev_counts[p] > 0 else t_start\n",
    "        \n",
    "#         # Build segment from last_time to t_end\n",
    "#         seg = np.linspace(last_time, t_end, added + 1, endpoint=True)[1:]\n",
    "#         seg = [int(s) if s.is_integer() else float(s) for s in seg]\n",
    "    \n",
    "#         # Grow travel_times if particles move through multiple grid cells\n",
    "#         # within one timestep\n",
    "#         if len(t_lists[p]) < list_len:\n",
    "#             t_lists[p].extend([None] * (list_len - len(t_lists[p])))\n",
    "    \n",
    "#         # Fill the list of timesteps\n",
    "#         t_lists[p][prev_counts[p]:list_len] = seg\n",
    "#         prev_counts[p] = list_len\n",
    "\n",
    "#     # Plotting\n",
    "#     fig, ax = plt.subplots(figsize=(10, 5), dpi=200)\n",
    "#     ax.scatter(yi, xi, c='firebrick', s=1)\n",
    "#     im = ax.imshow(particle.depth * -1, vmin=0, vmax=-25)\n",
    "#     plt.title(f'Time: {int((target_times[i] / 3600) // 24)} Days, {int((target_times[i] / 3600) % 24)} Hours')\n",
    "#     cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "#     cbar.set_label('Depth (m)')\n",
    "#     cbar.set_ticks([0, -5, -10, -15, -20, -25])\n",
    "#     cbar.set_ticklabels(['0', '5', '10', '15', '20', '25'])\n",
    "#     im.axes.xaxis.set_ticklabels([])\n",
    "#     im.axes.yaxis.set_ticklabels([])\n",
    "#     im.axes.get_xaxis().set_ticks([])\n",
    "#     im.axes.get_yaxis().set_ticks([])\n",
    "#     ax.set_facecolor('whitesmoke')\n",
    "#     plt.savefig(f'{path2folder}/output_by_dt{i}.png')\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d7277-6270-4ab4-a0f0-c92d35154a87",
   "metadata": {},
   "source": [
    "If you prefer not to run the code, a file containing the results can be found in this HydroShare [repository](https://doi.org/10.4211/hs.2301e151c62d4febb59655885458ab0c).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb214b3-b01f-40b5-941a-6f4b49de081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_folder / f'WalkData_{model_run}.txt', 'r') as f:\n",
    "    walk_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e54df46-8c71-427e-ac18-b06d1706e74e",
   "metadata": {},
   "source": [
    "Now that we have the walk history stored in `walk_data`, we can query this dictionary to extract features of interest. We can also convert the location indices back into geospatial coordinates using the function `particle_track.ind2coord()`. This function appends two additional fields to the dictionary: `['xcoord']` and `['ycoord']`, which represent particle positions in UTM coordinates, which may be useful for later plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da96cbce-f0de-4053-a4eb-bf0139898336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert particle location indices back into UTM coordinates\n",
    "walk_data = pt.ind2coord(walk_data, \n",
    "                         (min(unstructured['x']), \n",
    "                          min(unstructured['y'])), \n",
    "                         np.shape(elevation), resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c9a5c-09a5-4ea5-93fe-c13877a78a06",
   "metadata": {},
   "source": [
    "### Calculate exposure time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c0422-634a-403f-a9ed-48a72b45d70f",
   "metadata": {},
   "source": [
    "We want to measure the amount of time particles spent \"exposed\" within a Region of Interest (ROI), in our case, Lake Pontchartrain. We will use the region where particles were initially seeded as our area of interest. This allows us to evaluate how long particles remain within the system as a whole. Other ways of defining regions of interest can be found in `unstructured_grid_anuga.ipynb`. \n",
    "\n",
    "To compute this, we use the functions `particle_track.exposure_time()` and `routines.plot_exposure_time()`. These functions calculate and visualize the **Cumulative Distribution Function (CDF)** and the **Exposure Time Distribution (ETD)** based on particle interactions with a defined region of interest (ROI).\n",
    "\n",
    "First, we will compute the exposure times using the `exposure_time()` function. This function outputs a list of exposure times indexed by particle ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e25ab-4b5c-4b7e-a928-64aedc322f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_times = pt.exposure_time(walk_data, regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e008508-2c1c-48fc-9a2d-d106d736c58b",
   "metadata": {},
   "source": [
    "Now, we will visualize the results by calling `plot_exposure_time()`, which generates both the CDF and ETD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6eaec-9cd0-404b-8bb6-9fe4f046efb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exposure_times_plot = dorado.routines.plot_exposure_time(walk_data, \n",
    "                                                         exposure_times, \n",
    "                                                         f'{path2folder}/{model_run}/figs', # Output location for figures\n",
    "                                                         timedelta=86400, # timestep for model in seconds (1 day = 86400 seconds)\n",
    "                                                         nbins=10, # Binning for CDF exposure time\n",
    "                                                         uniform_timesteps = True) # This should be toggled to 'True' when the process used in this\n",
    "                                                                                   # notebook for unsteady data is used. Only toggle this if exposure\n",
    "                                                                                   # timesteps were discretely assigned. Otherwise use default (False)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec659b4-2d7d-4475-a0f9-75c7f4e720b6",
   "metadata": {},
   "source": [
    "**Note:** If any particles are still in the ROI at the end of their travel history, they are excluded from plots. These particles are not done being \"exposed,\" so we need to run more iterations in order to capture the tail of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cebc9d6-5bdf-4ad2-93c5-2225c8b6fdbc",
   "metadata": {},
   "source": [
    "## Save `walk_data` for use with additional model capabilities\n",
    "\n",
    "If you plan to use extended features of the model, such as reprocessing particle paths, calculating spatial exposure time, or generating animations, be sure to save the `walk_data` dictionary for future use.\n",
    "\n",
    "**Note:** While this function returns a `walk_data` dictionary, the same information is also stored as an attribute of the `particles` class and can be accessed via `particle.walk_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f40a3-7a01-4fb0-8649-7186e110b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.dump(walk_data, open(data_folder / f'WalkData_{model_run}.txt', 'w')) # only save if creating a new one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc58e5d3-8b87-4e9f-86cc-307d4e42553e",
   "metadata": {},
   "source": [
    "Save the following variables if you plan to run spatial exposure time calculations using `spatial.py`, where a walkthrough can be found in `spatial_exposure_time_example_Delft3DFM.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab246a3-d85f-4325-9c26-bdd28ababa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(data_folder / f'unstructured_model_Delft3DFM_variables_{model_run}.npz', elevation=elevation, celltype = celltype_roi, exposure_times = exposure_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f7a555-1266-43c8-bf70-bb744cd3a407",
   "metadata": {},
   "source": [
    "If you have any questions, feel free to contact Caitlin R. R. Turner at cturn65@lsu.edu "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e2e7d7-4360-4021-855f-47659f2de7af",
   "metadata": {},
   "source": [
    "#### **Cited:**\n",
    "Turner, C. R. R. (2025). Lake Pontchartrain Toy Model, HydroShare, https://doi.org/10.4211/hs.2301e151c62d4febb59655885458ab0c\n",
    "\n",
    "Turner, C. R. R., & Hiatt, M. (2025a). Water exposure time distributions controlled by freshwater releases in a semi-enclosed estuary. Water Resources Research, 61 (7), e2025WR040287, https://doi.org/10.1029/2025WR040287\n",
    "\n",
    "Turner, C. R. R., & Hiatt, M. (2025b). Water exposure time distributions controlled by freshwater releases in a semi-enclosed estuary published in water resources research wrr 2025 data. Hydroshare. https://doi:10.4211/hs.f1c83ff830bb47c5a7c84e6f5217ea5c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd9703-0a33-4383-aaa6-9e12e2937b0c",
   "metadata": {},
   "source": [
    "#### **Acknowledgments:**\n",
    "This work has been partially supported with funding provided by the Louisiana Sea Grant College Program (LSG) under its Competitive Research Program (Project ID: R/TMA-03) and NOAA Award No. NA18OAR4170098, and through the US Department of Defense/Army Engineer Research and Development Center (ERDC) under Contract No. W912HZ2220005. Additional support was provided from the National Science Foundation (NSF) through Open Earthscape (Collaborative Research: Frameworks: OpenEarthscape - Transformative Cyberinfrastructure for Modeling and Simulation in the Earth-Surface Science Communities) under its Summer Research Scholars Program under award No. 2104102."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dorado_updates)",
   "language": "python",
   "name": "dorado_updates"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
